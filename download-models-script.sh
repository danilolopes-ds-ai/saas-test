#!/bin/bash
# Script para download de modelos de IA para LocalAI

# Criar diretÃ³rio para modelos se nÃ£o existir
mkdir -p infrastructure/localai/models

echo "ðŸ¤– Iniciando download dos modelos para LocalAI..."

# FunÃ§Ã£o para verificar se modelo jÃ¡ existe
model_exists() {
    if [ -f "infrastructure/localai/models/$1" ]; then
        return 0 # Existe
    else
        return 1 # NÃ£o existe
    fi
}

# Download do modelo Phi-3-mini
PHI3_MINI="phi-3-mini-4k-instruct.Q4_K_M.gguf"
if ! model_exists "$PHI3_MINI"; then
    echo "ðŸ“¥ Baixando modelo Phi-3-mini..."
    curl -L "https://huggingface.co/TheBloke/phi-3-mini-4k-instruct-GGUF/resolve/main/phi-3-mini-4k-instruct.Q4_K_M.gguf" \
        -o "infrastructure/localai/models/$PHI3_MINI"
    echo "âœ… Download do Phi-3-mini concluÃ­do!"
else
    echo "âœ… Modelo Phi-3-mini jÃ¡ existe. Pulando download."
fi

# Download do modelo de embeddings
MINILM="all-MiniLM-L6-v2.gguf"
if ! model_exists "$MINILM"; then
    echo "ðŸ“¥ Baixando modelo de embeddings MiniLM..."
    curl -L "https://huggingface.co/abetlen/all-MiniLM-L6-v2-GGUF/resolve/main/all-MiniLM-L6-v2.F16.gguf" \
        -o "infrastructure/localai/models/$MINILM"
    echo "âœ… Download do MiniLM concluÃ­do!"
else
    echo "âœ… Modelo MiniLM jÃ¡ existe. Pulando download."
fi

# Download do modelo falcon (opcional para summarization)
FALCON="gpt4all-falcon-q4_0.gguf"
if ! model_exists "$FALCON"; then
    echo "ðŸ“¥ Baixando modelo Falcon..."
    curl -L "https://huggingface.co/TheBloke/gpt4all-falcon-gguf/resolve/main/gpt4all-falcon-q4_0.gguf" \
        -o "infrastructure/localai/models/$FALCON"
    echo "âœ… Download do Falcon concluÃ­do!"
else
    echo "âœ… Modelo Falcon jÃ¡ existe. Pulando download."
fi

echo "ðŸŽ‰ Todos os modelos foram baixados com sucesso!"
echo "ðŸ“‚ Os modelos estÃ£o em: infrastructure/localai/models/"
echo "ðŸš€ VocÃª pode iniciar o ambiente com: docker-compose up -d"